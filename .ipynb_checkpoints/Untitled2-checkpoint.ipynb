{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a57abeed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nIn the supervised regression framewor used for this data analysis case,\\nthe weekly return of TSLA stock is the predicted variable.\\nWe will try to understand what affects TSLA stock price and incorporate as much\\ninformation into the model. In this case study, we will focus on correlated assets as features.\\nFor upcoming study cases, we will use technical indicators and fundamental analysis.\\n\\nFor this case study, other than the historical data of TSLA, the independent variables\\nused are the following correlated assets:\\n -> Stocks: NIO and GM\\n -> Currency : USD/JPY and GBP/USD\\n -> Indices : S&P 500, Dow Jones, and VIX\\n\\nThe dataset used for this case study is extracted from Yahoo Finance and the FRED\\nwebsite.\\n'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1 - Problem definition\n",
    "\n",
    "\"\"\"\n",
    "In the supervised regression framewor used for this data analysis case,\n",
    "the weekly return of TSLA stock is the predicted variable.\n",
    "We will try to understand what affects TSLA stock price and incorporate as much\n",
    "information into the model. In this case study, we will focus on correlated assets as features.\n",
    "For upcoming study cases, we will use technical indicators and fundamental analysis.\n",
    "\n",
    "For this case study, other than the historical data of TSLA, the independent variables\n",
    "used are the following correlated assets:\n",
    " -> Stocks: NIO and GM\n",
    " -> Currency : USD/JPY and GBP/USD\n",
    " -> Indices : S&P 500, Dow Jones, and VIX\n",
    "\n",
    "The dataset used for this case study is extracted from Yahoo Finance and the FRED\n",
    "website.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "227af833",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nBelow we indicate the list of the libraries used for data loading, data analysis,\\ndata preparation, model evaluation, and model tuning.\\n'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2 - Loading the data and Python packages\n",
    "\n",
    "# 2.1. - Loading the Python packages\n",
    "\"\"\"\n",
    "Below we indicate the list of the libraries used for data loading, data analysis,\n",
    "data preparation, model evaluation, and model tuning.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "93ed0315",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function and modules for the supervised regression models\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "# Function and modules for data analysis and model evaluation\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2, f_regression\n",
    "\n",
    "# Function and modules for deep learning models\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasRegressor\n",
    "\n",
    "# Function and modules for time series models\n",
    "#from statsmodels import tsa\n",
    "#from tsa import arima as ARIMA\n",
    "#from statsmodels.tsa.arima import ARIMA\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# Function and modules for data preparation and visualization\n",
    "    # pandas, pandas_datareader, numpy and matplotlib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "#import pandas_datareader as web\n",
    "import pandas_datareader.data as web\n",
    "import pandas_datareader as pdr\n",
    "from matplotlib import pyplot\n",
    "from pandas.plotting import scatter_matrix\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from pandas.plotting import scatter_matrix\n",
    "from statsmodels.graphics.tsaplots import plot_acf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Yahoo for dataReader\n",
    "import yfinance as yf\n",
    "yf.pdr_override()\n",
    "\n",
    "# Datetime\n",
    "from datetime import *\n",
    "\n",
    "#Diable the warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "56810b7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "11d3bbe6",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-1-b919d0fe899c>, line 57)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-1-b919d0fe899c>\"\u001b[0;36m, line \u001b[0;32m57\u001b[0m\n\u001b[0;31m    Y = np.log(df_stock_data.loc[:,('Close', 'TSLA']).diff(return_period).shift(-return_period)\u001b[0m\n\u001b[0m                                                   ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# 2.2. - Loading the data\n",
    "stock_tickers = ['TSLA','NIO','GM']\n",
    "currency_tickers = ['DEXJPUS', 'DEXUSUK']\n",
    "idx_tickers = ['SP500', 'DJIA','VIXCLS']\n",
    "\n",
    "start_date = datetime(2018, 1, 1)\n",
    "end_date = datetime(2022, 5, 1)\n",
    "\n",
    "# Stock\n",
    "#stock_data = yf.download(stock_tickers,start=start_date,end=end_date)\n",
    "input_path_stock_data = '/Users/yousraaoudi/Desktop/TSLA_Data_analysis.py/stock_data.csv'\n",
    "df_temp_stock_data = pd.read_csv(input_path_stock_data,parse_dates=True,na_values=['nan']).dropna()\n",
    "df_stock_data = pd.DataFrame(data=df_temp_stock_data)\n",
    "print('Adj Close data describe \\n',df_stock_data['Adj Close'].dtype)\n",
    "     \n",
    "\"\"\"\n",
    "# Outliers - cleaning\n",
    "no_outlier_stock_data = df_stock_data[(np.abs(scipy.stats.zscore(df_stock_data)) < 3).all(axis=1)]\n",
    "print('Outliers Stock data describe \\n',no_outlier_stock_data.describe())\n",
    "df_stock_data = no_outlier_stock_data\n",
    "print('Stock data after removing outliers \\n',df_stock_data.head())\n",
    "\"\"\"\n",
    "\n",
    "# Currency\n",
    "#currency_data = web.get_data_fred(currency_tickers,start=start_date,end=end_date)\n",
    "input_path_currency_data = '/Users/yousraaoudi/Desktop/TSLA_Data_analysis.py/currency_data.csv'\n",
    "df_temp_currency_data = pd.read_csv(input_path_currency_data,parse_dates=True,na_values=['nan']).dropna()\n",
    "df_currency_data = pd.DataFrame(data=df_temp_currency_data)\n",
    "print('FX data describe \\n',df_currency_data.describe())\n",
    "\"\"\"\n",
    "# Outliers - cleaning\n",
    "no_outlier_currency_data = df_currency_data[(np.abs(scipy.stats.zscore(df_currency_data)) < 3).all(axis=1)]\n",
    "print('Outliers FX data describe \\n',no_outlier_currency_data.describe())\n",
    "df_currency_data = no_outlier_currency_data\n",
    "print('Currency data after removing outliers \\n',df_currency_data.head())\n",
    "\"\"\"\n",
    "\n",
    "# Indices\n",
    "#idx_data = web.get_data_fred(idx_tickers,start=start_date,end=end_date)\n",
    "input_path_idx_data = '/Users/yousraaoudi/Desktop/TSLA_Data_analysis.py/idx_data.csv'\n",
    "df_temp_idx_data = pd.read_csv(input_path_idx_data,parse_dates=True,na_values=['nan']).dropna()\n",
    "df_idx_data = pd.DataFrame(data=df_temp_idx_data)\n",
    "print('Indices data describe \\n',df_idx_data.describe())\n",
    "\n",
    "\"\"\"\n",
    "# Outliers - cleaning\n",
    "no_outlier_idx_data = df_idx_data[(np.abs(scipy.stats.zscore(df_idx_data)) < 3).all(axis=1)]\n",
    "print('Outliers - Indices data describe \\n',no_outlier_idx_data.describe())\n",
    "df_idx_data = no_outlier_idx_data\n",
    "print('Idx data after removing outliers \\n',df_idx_data.head())\n",
    "\"\"\"\n",
    "\n",
    "return_period = 5\n",
    "#Y = np.log(df_stock_data.loc[:,df_stock_data.loc('Adj Close', 'TSLA')]).diff(return_period).shift(-return_period)\n",
    "df_stock_data = df_stock_data.reset_index(drop=True)\n",
    "print('DF stock data \\n',df_stock_data.columns)\n",
    "Y = np.log(df_stock_data.loc[:,('Close', 'TSLA')]).diff(return_period).shift(-return_period)\n",
    "Y.name = Y.name[-1]+'_pred'\n",
    "\n",
    "X1 = np.log(df_stock_data.loc[:,('Close', ('F','GM'))]).diff(return_period)\n",
    "X1.columns = X1.columns.droplevel()\n",
    "X2 = np.log(df_currency_data).diff(return_period)\n",
    "X3 = np.log(df_idx_data).diff(return_period)\n",
    "\n",
    "X4 = pd.concat([np.log(df_stock_data.loc[:,('Adj Close','TSLA')]).diff(i)\n",
    "                for i in [return_period, return_period*3, return_period*6,\n",
    "                          return_period*12]], axis=1).dropna()\n",
    "X4.columns = ['TSLA_DT', 'TSLA_3DT', 'TSLA_6DT', 'TSLA_12DT']\n",
    "X = pd.concat([X1, X2, X3, X4], axis=1)\n",
    "\n",
    "dataset = pd.concat([Y,X], axis=1).dropna().iloc[::return_period,:]\n",
    "Y = dataset.loc[:,Y.name]\n",
    "X = dataset.loc[:, X.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b8c7631",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Exploratory data analysis\n",
    "\"\"\"\n",
    "In this section, we will look at descriptive statistics, data visualization,\n",
    "and time series analysis.\n",
    "\"\"\"\n",
    "\n",
    "# 3.1. - Descriptive statistics\n",
    "print('dataset \\n',dataset.head())\n",
    "print('Statistics \\n',dataset.describe())\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35fa74cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.2. Data visualization\n",
    "\"\"\"\n",
    "In order to learn more about our data, we will visualize it. \n",
    "Visualization involves independently understanding each attribute of\n",
    "the dataset. Therefore, we will look at the scatterplot and the correlation\n",
    "matrix. These plots will give us a sense of the interdependence of\n",
    "the data. Correlation can be can be calculated and displayed for each pair of the variables\n",
    "by creating a correlation matrix.\n",
    "Besides the relationship between dependent and independent variables, it also\n",
    "shows the correlation among the independent variables. \n",
    "\"\"\"\n",
    "dataset.hist(bins=50, sharex=False, sharey=False, xlabelsize=1, ylabelsize=1, figsize=(12,12))\n",
    "pyplot.show()\n",
    "\n",
    "dataset.plot(kind='density', subplots=True, layout=(4,4), sharex=True, legend=True, fontsize=1, figsize=(15,15))\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39e7e122",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation - To get a sense of data interdependence\n",
    "correlation = dataset.corr()\n",
    "pyplot.figure(figsize=(15,15))\n",
    "pyplot.title('Correlation Matrix')\n",
    "sns.heatmap(correlation,vmax=1,square=True,annot=True,cmap='cubehelix')\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d23970c6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
